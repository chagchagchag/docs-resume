{"/architecture-experience/if-project-again":{"title":"If Project Again","data":{"프로젝트를-다시-한다면#프로젝트를 다시 한다면":"상태없는 연산이 필요한 인스턴스에는 k8s 애플리케이션으로 전환\nwaiker-data-websocket, waiker-data-live\n메시지 큐, Spring Cloud Function\n카프카 기반의 메시지 큐로 전환\nMSA간 통신은 Event 기반으로\naxon\n비동기 논블로킹 지원 네트워크 프로그램으로 전환\nNetty 기반의 웹 애플리케이션으로 전환\nKotlin, Webflux 기반으로 전환"}},"/architecture-experience/consumer-thread-optimization":{"title":"Consumer Thread Optimization","data":{"스레드-최적화#스레드 최적화":""}},"/architecture-experience/major-issue":{"title":"Major Issue","data":{"주요-이슈#주요 이슈":"","필드-매핑의-어려움-멱등성#필드 매핑의 어려움, 멱등성":""}},"/architecture-experience/intro":{"title":"Intro","data":{"":"시스템을 직접 설계해서 MSA로 분해하고 각 서비스간 통신을 위해 메시지큐를 도입해나간 과정과 레피니티브의 시세 트래픽을 밀리지 않고 I/O 작업을 처리하기 위해 적용했던 설계방식, 문제해결 과정을 정리했습니다.","프로젝트-설명#프로젝트 설명":"한국증권거래소 처럼 증권 시세를 Serving 하는 레피니티브라고 하는 회사의 시세 데이터를 1차 가공한 후 웹소켓 Push, Database 저장하는 것을 담당하는 시스템입니다.","트래픽-규모#트래픽 규모":"트래픽은 아래와 같이 2.5k/s ~ 7.5k/s 였습니다.\n개장(Market Open) 트래픽 추이\n폐장(Markt Close) 트래픽 추이","주요-문제#주요 문제":"2.5k/s ~ 7.5k/s 의 트래픽을 밀리지 않고 데이터를 저장하고, 웹소켓을 통해 웹/앱 으로 Push 를 해야 했습니다.웹소켓 푸시, 데이터 저장에 드는 I/O 작업의 시간 비용은 고정적으로 소모되므로, 일반적인 서버 애플리케이션의 처리방식과는 다른 접근방식이 필요했습니다. 또한, 요청이 유실 되었을 경우 이것을 복구해낼 방법이 필요했는데 이 부분에 대한 접근방식도 필요했습니다."}},"/architecture-experience/message-queue-usage":{"title":"Message Queue Usage","data":{"메시지-큐-기반-시스템-분해작업#메시지 큐 기반 시스템 분해작업":"","레거시-데이터-처리-서버---valuesight#레거시 데이터 처리 서버 - valuesight":"웨이커에서는 레거시 버전의 데이터 처리서버를 신규 버전으로 새로 개편을 해야 했습니다. valuesight 는 쉽게 설명하면 아래와 같은 역할을 합니다.\n레피니티브로부터 실시간으로 전달되는 주식 거래 raw 데이터를 수신\nraw 데이터에 대한 현재가, 52주신고가, BID, ASK, 고가, 저가 등의 필드 매핑\n웹소켓으로 현재가 Push\n매핑된 데이터를 기반으로 일/시/분/초 별 저가/고가/시가/종가 데이터 집계\n집계된 데이터를 PostgreSQL 에 저장\n이 당시 valuesight 서버는 매일 새벽마다 서버가 다운되어서 개발자가 수동으로 재기동시키고, 비어있는 데이터를 크롤링을 통해서 매우고 있었습니다. valuesight WAS 코드에는 동기화/락 코드가 있었기 때문에 레피니티브에서의 시세 데이터 전송 속도를 개별 I/O 처리 작업이 따라가지 못하면서 어느 순간에는 더 이상 처리할 수 없는 상태에 자주 빠지게 되었습니다.저의 경우에는 레거시 데이터 처리 서버인 valuesight 의 운영에 대한 어떤 이슈가 있는지에 대한 정보를 거의 전달받지 못하고 신규버전 출시 2주일 전에 코드만 전달 받은 채로 프로젝트를 넘겨받아서 시작했습니다.레거시 서버의 신규 서버 전환 작업을 맡으면서 미리 개발자에게 언급 없이 레피니티브의 데이터 구독제를 바꿔서 상용에서 장애가 난 경험도 있었습니다. 이때 1주일간 로그를 추출한 후 필드매핑을 처음부터 일일이 한땀 한땀 떼어서 확인해서 다음날 미국장에 잘 되는지 확인해보던 잠 못자고 살 떨리던 경험도 있었고, M증권사의 개발팀 부장님과 컨택이 되서 구글 밋으로 회의를 하면서 실시간 데이터를 어떻게 처리하는 지에 대한 팁도 얻었던 경험이 있습니다.","overview#Overview":"미국 주식 시세 데이터를 처리하기 위해서 단계적으로 스레드 프로그래밍이 개선을 거듭했고, 최종적으로는 아래와 같은 구조가 되었습니다. 랩장님과 인프라팀의 인원들의 반대로 도입하지 못한 기술적인 면들이 많았지만, 시간내에 프로젝트를 완료시킬 수 있는 최적의 구조는 아래와 같았습니다.","서비스-역할-정의#서비스 역할 정의":"\"메시지 큐를 단순히 소비자와 생산자를 두는 것이 단순히 처리를 뒤로 미루는 용도로 사용하지 않아야 한다\"는 점에 집중해서 작업을 처리하는 구조와 메시지 소비 구조를 맞춰나가는 작업을 해왔습니다.","waiker-data-live#waiker-data-live":"레피니티브의 미국 주식 시세 데이터는 그 트래픽의 속도가 굉장히 빠릅니다. 이것을 온전히 데이터를 큐잉 하는 작업만으로도 부하가 상당했습니다. 이런 이유로 레피니티브의 raw 데이터를 우리팀의 구조에 맞춰서 변환하는 작업과 RabbitMQ에 지연 없이 전송이 가능하는 역할만을 전담하는 인스턴스인 waiker-data-live 를 별도로 두었습니다.\n레피니티브 raw 데이터 필드맵 변환\n데이터타입 정형화\n변환한 데이터를 RabbitMQ에 큐잉\nwaiker-data-live 는 서비스의 가장 앞단에서 원본 데이터를 서빙하는 역할을 합니다.레피니티브의 미국 주식 트래픽이 꽤 높기 때문에 앞단에서 원본 데이터만 서빙하는 역할의 서버를 따로 분리해야 했습니다.\n데이터 타입 정형화이 당시 레피니티브의 공식 문서를 찾거나 레피니티브 개발자 포럼에 질문을 남겨서 특정 필드가 나노세컨드 단위인지 밀리세컨드인지, 정수형 타입, 실수형 타입에는 어떤 것들이 있는지를 모두 확인해서 맞춰둔 후에 데이터타입을 포매팅하는 과정을 거쳤습니다.혹시라도 이 글을 읽는 분들 중 레피니티브 데이터 개발 업무를 수행하는 데에 도움이 될 수도 있는 분들이 있을것 같아서 그 코드의 일부를 남겨보면 아래와 같습니다.\n@Slf4j\r\n@Getter\r\npublic class FieldEntryUtils {\r\n    // ...\r\n    \r\n\tprivate final Function<FieldEntry, String> fieldEntryToStr_Function = (fieldEntry -> {\r\n        // 자체 정의한 switch ~ case 문에 존재하지 않는 타입도 String 으로 일단 받아서 확인하기 위해 추가\r\n\t\tString str = fieldEntry.load().toString(); \r\n\r\n\t\tswitch (fieldEntry.loadType()) {\r\n\t\t\tcase DataTypes.UINT, DataTypes.UINT_1, DataTypes.UINT_2, DataTypes.UINT_4, DataTypes.UINT_8 -> {\r\n\t\t\t\tlong l = fieldEntry.uintValue();\r\n\t\t\t\tstr = String.valueOf(l);\r\n\t\t\t}\r\n\t\t\tcase DataTypes.INT -> {\r\n\t\t\t\tlong l = fieldEntry.intValue();\r\n\t\t\t\tstr = String.valueOf(l);\r\n\t\t\t}\r\n\t\t\tcase DataTypes.REAL, DataTypes.REAL_4RB, DataTypes.REAL_8RB -> {\r\n\t\t\t\tdouble v = fieldEntry.real().asDouble();\r\n\t\t\t\tstr = String.valueOf(v);\r\n\t\t\t}\r\n\t\t\tcase DataTypes.DOUBLE, DataTypes.DOUBLE_8, DataTypes.FLOAT, DataTypes.FLOAT_4 -> {\r\n\t\t\t\tdouble v = fieldEntry.doubleValue();\r\n\t\t\t\tstr = String.valueOf(v);\r\n\t\t\t}\r\n\t\t\tcase DataTypes.DATE -> {\r\n\t\t\t\tif(fieldEntry.date().day() == 0) {\r\n\t\t\t\t\tstr = LocalDate.of(fieldEntry.date().year(), fieldEntry.date().month(), 1).format(ServerStockTime.formatter);\r\n\t\t\t\t}\r\n\t\t\t\telse{\r\n\t\t\t\t\tLocalDate date = LocalDate.of(fieldEntry.date().year(), fieldEntry.date().month(), fieldEntry.date().day());\r\n\t\t\t\t\tstr = String.valueOf(date.format(ServerStockTime.formatter));\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcase DataTypes.TIME -> {\r\n\t\t\t\tLocalTime time = LocalTime.of(fieldEntry.time().hour(), fieldEntry.time().minute(), fieldEntry.time().second(), fieldEntry.time().nanosecond());\r\n\r\n\t\t\t\tlong l = time.toNanoOfDay();\r\n\t\t\t\tstr = String.valueOf(l);\r\n\t\t\t}\r\n\t\t\tcase DataTypes.DATETIME -> {\r\n\t\t\t\tstr = fieldEntry.dateTime().toString();\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\treturn str;\r\n\t});\r\n}\n데이터 구조일반적인 상용 서비스나 현실세계의 데이터가 아니어서 이해는 어렵겠지만, 당시에 사용했던 데이터의 구조는 아래와 같았습니다.\npublic class FieldEntryDto implements Serializable {\r\n    private String ric;\r\n\tprivate String nbRic;\r\n\tprivate Map<String, String> fieldMap;\r\n\tprivate SymbolDto symbolDto;\r\n    // ...\r\n}\n그 당시 사용하던 Java 16 에서는 record 키워드가 preview 였고, 이 기능에 record 를 기반으로 전환할 지 고민을 거듭하다가 일반 class 기반으로 두었는데, 아마도 프로젝트를 다시 한다면 record 기반으로 구현하지 않았을까 싶습니다.그 당시 메시지 큐를 카프카를 사용하는 것이 아니었기에 파티셔닝에 대해 고민하지 않았다는 점은 확실히 장점이었던 것 같습니다.\n아쉬웠던 점waiker-data-live 의 경우 상태가 있는 서버 애플리케이션이 아니기에 EKS로 전환이 쉽고, 저 역시도 EKS 전환이 시급하다고 느껴왔던 프로젝트였지만, 이 당시 개발 기한문제도 있었고 EKS를 운영할 데브옵스 팀의 인력문제로 인해 k8s 네이티브 앱으로 전환하지 못한점이 가장 큰 아쉬움으로 남는 서비스입니다.","waiker-data-collector#waiker-data-collector":"waiker-data-collector 는"}},"/architecture-experience/test-case-experience":{"title":"Test Case Experience","data":{"테스트케이스-경험#테스트케이스 경험":"","필드-매핑-파악의-어려움--로그-추출--필드매핑-테스트-코드#필드 매핑 파악의 어려움 : 로그 추출 & 필드매핑 테스트 코드":""}},"/":{"title":"Introduction","data":{"":"Ctrl + 마우스 휠 아래 스크롤 을 통해서 페이지 확대 비율을 90%로 축소해서 맞춰주시면, 훨씬 더 깔끔하게 보입니다."}},"/portfolio/portfolio":{"title":"Portfolio","data":{"":"Spring Webflux, Kotlin Coroutine\nhttps://chagchagchag.github.io/docs-spring-webflux/\nhttps://chagchagchag.github.io/docs-kotlin-coroutine/\nMySQL\nhttps://chagchagchag.github.io/docs-mysql-essential/\nk8s, EKS, ArgoCD\nhttps://chagchagchag.github.io/docs-fibonacci-backend/\nhttps://chagchagchag.github.io/docs-argocd-setup-at-eks/\nhttps://chagchagchag.github.io/argocd-rollout-deploy-docs/\nJava\nhttps://chagchagchag.github.io/docs-study-java/\netc\nRedis,MySQL 기반 쿠폰발급기 : https://chagchagchag.github.io/docs-coupon-service/\nEDA 기반 Spring Cloud : https://chagchagchag.github.io/eda-based-spring-cloud-doc/"}},"/project-history/problem-solving-histories":{"title":"Problem Solving Histories","data":{"경력기술서#경력기술서":"","웨이커-202106--202206#웨이커 (2021.06 ~ 2022.06)":"","신규-서비스-api-개발#신규 서비스 API 개발":"레거시 서비스(valuesight)의 종료로 인한 신규서비스(waiker)의 API 개발업무를 진행했습니다.대가들의 분석, 뉴스, 주요재무, AI종목분석, 종목정보 등 주식 탭에 존재하는 API 개발을 담당했고 주로 AI 개발자 분들의 분석 데이터, 크롤링 데이터를 쌓아두기 위한 테이블 설계, 웹/앱에서 데이터 조회를 위한 API 구현 등이 주된 업무였습니다.","레피니티브-증권-시세-데이터-처리-시스템-구축#레피니티브 증권 시세 데이터 처리 시스템 구축":"","프로젝트-설명#프로젝트 설명":"한국증권거래소 처럼 증권 시세를 Serving 하는 레피니티브라고 하는 회사의 시세 데이터를 1차 가공한 후 웹소켓 Push, Database 저장하는 것을 담당하는 시스템입니다.","트래픽-규모#트래픽 규모":"트래픽은 아래와 같이 2.5k/s ~ 7.5k/s 였습니다.\n개장(Market Open) 트래픽 추이\n폐장(Markt Close) 트래픽 추이","주요-문제#주요 문제":"2.5k/s ~ 7.5k/s 의 트래픽을 밀리지 않고 데이터를 저장하고, 웹소켓을 통해 웹/앱 으로 Push 를 해야 했습니다.웹소켓 푸시, 데이터 저장에 드는 I/O 작업의 시간 비용은 고정적으로 소모되므로, 일반적인 서버 애플리케이션의 처리방식과는 다른 접근방식이 필요했습니다. 또한, 요청이 유실 되었을 경우 이것을 복구해낼 방법이 필요했는데 이 부분에 대한 접근방식도 필요했습니다.","메시지-큐-기반-작업-분배-방식-도입#메시지 큐 기반 작업 분배 방식 도입":"작업의 성격별로 서버 애플리케이션을 3가지로 분류해서 아래와 같이 나눴고, 각각이 별도의 서버 애플리케이션으로 동작하도록 구성했습니다.\nwaiker-data-live\n레피니티브 raw 데이터 수신\n거래시각데이터를 LocalTime, LocalDate 기반 의 데이터로 변환\n변환된 RabbitMQ 메시지 큐에 데이터 적재\nwaiker-data-collector\n필드 매핑 작업 (가장 어려운 작업입니다.)\n일/시/분/초 단위 별 시가/고가/종가/저가 계산\noffheap 캐시 적재\nPostgreSQL 에 집계 데이터 저장\nwaiker-data-websocket\n웹/앱 단말로 웹소켓 푸시 작업 처리\n웹/앱 단말이 많아질 수록 부하가 높아지는 인스턴스","스케쥴링-기반의-소규모-배치작업-구조로-전환#스케쥴링 기반의 소규모 배치작업 구조로 전환":"코틀린의 코루틴이 스레드 하나를 여러개의 코루틴으로 나누어서 CoroutineDispatcher 가 코루틴의 실행/중지/재개/종료를 담당하는 것과 비슷한 원리를 스레드 풀 관리로직에 적용했습니다. ExecutorService 스레드 풀을 작게 잡고 이것을 스케쥴러 스레드를 이용해서 작업을 스케쥴링하고 각각의 작업을 CompletableFuture 를 이용해서 비동기 처리하는 방식으로 문제를 해결했습니다.","더-자세한-내용#더 자세한 내용":"웨이커에서 마지막으로 수행했던 증권 시세 데이터 처리 프로젝트는 별도의 설명이 필요해서 별도의 문서에 더 자세한 내용을 정리해두었습니다.\nTODO","디케이테크인-201911--202106#디케이테크인 (2019.11 ~ 2021.06)":"디케이테크인에서는 아래와 같은 업무들을 수행했습니다.\n뮤직 DNA 6.0 개편 : 월간/주간 개인 선호음악/추천음악 조회 백엔드 API 개발\n피드, 마이로그 6.0 개편 : 개인화 영역 소식 내역 메시지 생성 기능 개발\n멜론 댓글 서비스 운영/유지보수\n슬로우 쿼리 유지보수/대응\n카카오 클린플랫폼 연동 블랙리스트 기능 개발\n멜론 HiFi/음원/스테이션/카카오뮤직/계정 유지보수\n상용서비스를 개발하는 개발 유닛에서 함께 개발에 참여했고, 그 당시 생소한 개념이었던 Resilience4J 의 서킷브레이커 등의 Spring Cloud 개념들을 내부 개발 유닛의 개발 문서를 통해 접해보기도 했었고 카카오 클린 플랫폼의 블랙리스트 기능 연동시 이 기능을 적용했던 경험이 있습니다.디케이테크인에서 멜론 운영업무를 하면서 카카오 개발자 공채 출신 직원 분도 뵜었고, 멜론 출신 개발자 분들도 뵜었고, 기획자 분들도 뵜었고 이 외에도 굉장히 다양한 분들을 접했습니다. 멜론 개발 셀은 항상 스터디하는 습관이 베어있던 개발 조직이었기에 여기서 보고 배운 습관이 평소에도 기술 스터디를 꾸준히 하는 습관으로 이어졌습니다.","멜론-키즈-프로모션이-스테이션-배너에-랜딩되지-않던-이슈#멜론 키즈 프로모션이 스테이션 배너에 랜딩되지 않던 이슈":"스테이션 배너 앱 랜딩에 멜론 키즈의 프로모션이 랜딩되지 않는 이슈가 있었습니다. 멜론모바일, 멜론웹, 멜론 공통 모듈까지 모두 검사해서 어떤 부분이 잘못되었는지 찾아가는 과정을 겪었고, 결론은 멜론 어드민 내의 상수 코드 값이 빠져있어서 생기는 이슈였다는 것을 파악했습니다.결론은 굉장히 쉬워보이지만 워낙 많은 인원들의 입사와 퇴사를 거친 레거시 코드이기에 버그의 원인을 찾는데에 2주 반 정도 소요됐었고, 이 버그에 대한 히스토리조차도 없이 맨땅에서부터 시작해서 문제를 해결해나갔었기에 가장 어려웠던 경험이었습니다.","누리플렉스-201801--201911#누리플렉스 (2018.01 ~ 2019.11)":"누리플렉스에서는 아래와 같은 업무들을 수행했습니다.SK E&S STEP 에너지 모니터링 솔루션 개발/운영업무\n장비 개별정보 현황/이력(통계) 데이터 조회 API 설계/구현\n데이터 시각화 (차트라이브러리, 그리드 라이브러리 연동 등)\nSUSTERA PMS 에너지 모니터링 솔루션 개발/운영\n장비 개별정보 현황/이력(통계) 데이터 조회 API 설계/구현\n데이터 시각화 (차트라이브러리, 그리드 라이브러리 연동 등)\nCJ/부산 신재생 에너지 혁신센터 EMS 운영/유지보수\nMQ 데이터 트래픽 서버의 잦은 장애로 인한 SockJS 측에서의 예외처리\n이슈 및 개별 장애 대응\n위 업무 들 중 가장 기억에 남았던 문제해결 경험은 CJ/부산 신재생 에너지 혁신센터 EMS 운영/유지보수 시에 겪었던 MQ 데이터 트래픽 서버 장애 처리 경험입니다.","mq-데이터-트래픽-서버-장애에-대한-sockjs-타임아웃-처리#MQ 데이터 트래픽 서버 장애에 대한 SockJS 타임아웃 처리":"CJ/부산 신재생 에너지 혁신센터 시스템 운영 당시 개발팀에는 한전이나 LS로부터 전달받는 소켓 데이터를 Active MQ를 통해 웹소켓 데이터로 발송하거나 DB에 데이터를 INSERT하는 IO 작업을 담당하는 개발자 분이 계셨습니다. 한전/LS 로부터 전달받는 단건 데이터의 빈도에 비해 웹소켓/데이터저장 처리 속도가 물리적으로 느리기에 전기요금이 경부하 기간인 새벽시간 대에는 전기 충전 트래픽이 몰려 서버가 다운되는 현상이 있었습니다.이런 이유로 MQ서버 개발자 분께서는 야간에 자주 서버를 재기동하셨습니다.당시 저는 WAS 측의 운영을 담당하고 있었습니다. 서버 재기동이 영향을 주던 기능은 ESS 충방전현황 대시보드 내의 실시간 충전현황과 외기 온도를 보여주는 기능이었습니다. 서버를 재기동하기에 웹소켓 커넥션이 유실되는 것으로 인해 UI상으로는 관련된 기능이 다운된 것처럼 보이는 현상이 있었습니다.이 문제에 대해 ‘소켓 접속이 끊어지더라도 주기적으로 서버에 재접속 요청을 하도록 구성하는 것’ 이라는 점에 포인트를 주어 해결해야겠다는 결론을 내렸습니다. 그리고 SockJS 공식 문서를 참고해 SockJS의 내부 코드 중 디폴트 설정을 파악해서 디폴트 설정을 수정하고 기본으로 제공되는 SockJS 내부 코드의 일부분을 커스터마이징 해 문제를 해결했습니다. 수정했던 디폴트 설정은 ‘네트워크 커넥션 타임아웃 기간’, ‘재접속 Retry 주기’ 등 이었고, 무한대로 접속 요청을 하는 것으로 인한 부하 역시 줄여야 하기에 ‘재접속 횟수’에 제한을 걸어서 재접속 요청을 하도록 SockJS 소스코드를 수정해 배포했습니다.MQ 서버 처리로직에 안정성에 문제가 많았고 결함이 많았지만, 클라이언트 측(SockJS)의 코드를 유연하게 구성해서 제품의 문제가 발생하더라도 유연하게 장애에 대응했던 경험이라고 생각합니다.","주니코리아-201505--201704#주니코리아 (2015.05 ~ 2017.04)":"3G/4G 무선신호를 WIFI 로 변환해주는 기업용 데이터 네트워크 라우터들의 모니터링, 관리/제어를 위한 솔루션 유지보수/개발 업무를 해왔습니다.Hardware Replacement (TELSTRA)\nJAVA GUI, TCP/IP 통신 로직 개발\nHEMS 유지보수/개발/운영\nQA 대응, 유지보수/개발/운영, 트러블 슈팅","논블로킹-처리-경험#논블로킹 처리 경험":"Java GUI 애플리케이션에서 TCP/IP 통신 로직을 작성할 때 주로 외부 API를 호출할 때 GUI에 관련된 메인 스레드를 IO작업이 블로킹하지 않도록 로직을 구현하는 작업들이 많았습니다. 예를 들면 네트워크 설정파일(json, xml)의 SFTP Upload/Download 를 진행과 동시에 프로그래스바 UI에 진행률을 표시하는 기능을 구현하는 등의 작업 등을 해왔습니다."}},"/project-history/project-history":{"title":"Project History","data":{"프로젝트-수행-기록#프로젝트 수행 기록":"","waiker#waiker":"재직기간 : 2021.06 ~ 2022.06","waiker-증권-플랫폼-구축#waiker 증권 플랫폼 구축":"프로젝트 기간 : 2021.06 ~ 2021.11\nJava, SpringBoot, JPA, JdbcTemplate, Querydsl, Postgresql, Redis\nvaluesight 서비스 종료에 따른 신규 서비스 개발\n투자대가들의 점수, AI 스코어 등 주식 탭 API 및 데이터 개발\n테이블 설계, REST API 신규개발, QA, 내부 로직 고도화","레피니티브-증권-시세-데이터-처리-시스템-구축#레피니티브 증권 시세 데이터 처리 시스템 구축":"프로젝트 기간 : 2021.12 ~ 2022.06\nJava, SpringBoot, Spring AMQP, RabbitMQ, Postgresql, Java, JdbcTemplate, JPA,\r\nHazelcast\n레피니티브 시세 데이터 트래픽 처리 (미국, 중국)\n고빈도 트래픽(2.5k/s ~ 7.5k/s)의 I/O 처리 효율화 설계/개발/리팩토링 (웹소켓, 데이터저장)\nRAW 데이터 매핑, 추출, 테스트 케이스 작업\n프로젝트 전반적으로 테스트 커버리지 80% 가 되도록 테스트 커버리지 작업 수행 및 리팩토링","디케이테크인#디케이테크인":"재직기간 : 2019.11 ~ 2021.06","멜론-음원-시스템-서비스-운영#멜론 음원 시스템 서비스 운영":"운영 기간 : 2019.11 ~ 2021.06\nJava, Javascript, JQuery, Kotlin, Spring, SpringBoot, Mybatis, JPA, Memcached\n멜론 HiFi, 멜론 댓글, 댓글 어드민, 멜론 어드민, 카카오뮤직 등의 내부 업무들 티켓 기반 유지보수/운영\n레거시 개편 업무","누리플렉스#누리플렉스":"재직기간 : 2018.10 ~ 2019.11","sk-es-에너지-모니터링-시스템-구축#SK E&S 에너지 모니터링 시스템 구축":"프로젝트 기간 : 2019.04 ~ 2019.11\nJava, Javascript, JQuery, Spring, SpringBoot, Amchart, Oracle, MySQL, Mybatis\n에너지 모니터링 시스템 구축\n장비현황, 장비이력 기능 백엔드, 프론트엔드 개발 담당\nEMS/TOC 사업장 대시보드 개발","sustera-pv-ess-모니터링-시스템-구축#SUSTERA PV ESS 모니터링 시스템 구축":"프로젝트 기간 : 2018.12 ~ 2019.02\nJava, Javascript, JQuery, Spring, Amchart, Oracle, MySQL, Mybatis\n에너지 모니터링 시스템 구축\n장비현황, 장비이력 관련 백엔드, 프론트엔드 개발 담당","cj-pcc-부산-신재생에너지-혁신센터-에너지-모니터링-시스템-운영#CJ PCC 부산 신재생에너지 혁신센터 에너지 모니터링 시스템 운영":"운영 기간 : 2018.10 ~ 2019.11\nJava, Javascript, JQuery, Spring, SpringBoot, AngularJS, Amchart, Morris Chart, Oracle, MySQL, Mybatis\n웹소켓 장애 대응, Frontend 유지보수\nESS 충방전 현황 대시보드 개발","주니코리아#주니코리아":"재직기간 : 2015.05 ~ 2017.04","hardware-replacement-telsta#Hardware Replacement (TELSTA)":"프로젝트 기간 : 2015.09 ~ 2016.01\nJava, TCP/IP, SWT/JFace\nLTE 중계기 관제솔루션\nTCP/IP 통신 로직 & 화면 렌더링 로직 개발","프리랜서#프리랜서":"","블록체인-서비스-운영-프리랜서#블록체인 서비스 운영 (프리랜서)":"2023.06 ~ 2023.08\nKotlin, Springboot, MySQL, RestDocs, Ganache, Web3j, ethereum\n금융권 블록체인 서비스 운영업무 (프리랜서)"}},"/work-history/retire-reason":{"title":"Retire Reason","data":{"퇴직-사유#퇴직 사유":"","웨이커#웨이커":"업무의 과중함이 컸고, 신체적으로도 이상신호가 와서 별도의 이직 준비기간 없이 퇴직신청서를 내고 퇴사를 했습니다.","디케이테크인#디케이테크인":"멜론 서비스를 운영하고 전방위적인 이슈들을 처리하고 해결해나가는 데에 소소한 기쁨을 느껴왔지만, 멜론 운영/개발 업무가 아닌 테스트 프레임워크 구축 등의 업무가 점점 늘어왔고 레거시 개편/운영보다는 새로운 프로젝트를 해보고 싶다는 생각이 들어서 웨이커에서의 이직제안을 수락하고 디케이테크인에서 퇴사를 하게 되었습니다.","누리플렉스#누리플렉스":"그 당시 2017 ~ 2019 년도 당시 ESS 신규사업들을 하던 사업부에서 신규 프로젝트를 2건을 해왔습니다. 이 당시 영업부서와 함께 일했기에 개발팀의 업무가 개별 영업 건에 자주  휘둘리는 점까지는 이해가 갔지만, 지나치게 잦은 회식으로 인해 업무에 큰 영향을 자주 받아왔습니다.적은 인력으로 프로젝트를 완수해가던 그 당시 환경으로서는 일정을 지키기 위해 수면도 꽤 부족했고, 체력적으로 부담이 커서 퇴사를 결정하게 되었습니다.","주니코리아#주니코리아":"JAVA 기반의 TCP/IP 통신기반의 프로젝트를 운영해왔는데, 진로를 백엔드 개발 분야로 결정하면서 퇴사를 결정했습니다."}},"/work-history/work-history":{"title":"Work History","data":{"재직기록#재직기록":"","웨이커#웨이커":"2021.06 ~ 2022.06\nBackend 개발\nJava, Spring Boot, JPA, Querydsl, JdbcTemplate, Redis, Hazelcast, RabbitMQ, Spring AMQP\n증권 분석 플랫폼 신규 개발\n레피니티브 증권 거래 데이터 처리 서버 개발 & 트래픽 IO 최적화","디케이테크인#디케이테크인":"2019.11 ~ 2021.06\nBackend 개발\nJava, Javascript, JQuery, Kotlin, Spring, SpringBoot, Mybatis, JPA, Memcached\n상용 시스템 운영 (멜론)\n지금은 서비스가 종료되었지만 멜론의 HiFi 담당자 였습니다.\n멜론 댓글, 댓글 어드민, 멜론 어드민, 카카오뮤직 등의 내부 업무들을 티켓 기반 유지보수/운영\n서비스 운영시 발생하는 수없이 많은 각종 버그들 처리, 다크모드 지원 작업 등등","누리플렉스#누리플렉스":"2018.10 ~ 2019.11\nBackend 개발\nJava, Javascript, JQuery, Spring, SpringBoot, AngularJS, Amchart, Morris Chart, Oracle, MySQL, Mybatis\n구축\nSUSTERA PV ESS 모니터링 시스템 구축\nSK E&S 에너지 모니터링 시스템 구축\n유지보수/운영\nCJ, 부산 신재생 에너지 혁신센터","주니코리아#주니코리아":"2015.05 ~ 2017.04\nJava 개발\nJava, TCP/IP, SWT/JFace\n개발\nHardware Replacement (TELSTA)\n네트워크 노드 모니터링/제어 시스템 운영/개발","프리랜서#프리랜서":"","블록체인-서비스-운영#블록체인 서비스 운영":"2023.06 ~ 2023.08 (계약종료)\n금융권 블록체인 서비스 운영업무(프리랜서)\nBackend 개발\nKotlin, Springboot, MySQL, RestDocs, Ganache, Web3j, ethereum"}}}