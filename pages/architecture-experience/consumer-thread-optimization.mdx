## 스레드 최적화

흔히 트래픽이 높으면 스레드를 높여야 한다는 착각에 빠질 수 있습니다. 하지만 개발을 해보면서 느낀 점은 각각의 로직이 비동기적으로 논블로킹연산이 되도록 구현을 하면 스레드 개수가 그렇게 많을 필요가 없었다는 점이었습니다. <br/>

이렇게 정의한 비동기 논블로킹 연산의 람다 바디 정의부는 캐시에 데이터를 쌓아두는 생산자와 캐시의 데이터를 일정 사이즈 만큼 읽어들여서 소비하는 소비자를 함께 구현해두면, 서로가 서로의 작업을 블로킹하지 않고 별도의 ExecutorService 내에서 Async 하게 동작하기 때문에 애플리케이션 레벨에서의 교착현상은 사라집니다.<br/>

제 경우에는 스케쥴러 Executor 와 작업을 수행하는 workerExecutor, RabbitMQ 의 데이터를 receive 하는 listenerExecutor 로 분류해서 각각을 관리했습니다.

- schedulerExecutor : 작업 조율 스레드
- workerExecutor : 데이터 저장작업
- pushExecutor : 데이터 Push 역할 담당
- listenerExecutor : 데이터 수신 역할 담당

<br/>

레피니티브의 고빈도 트래픽을 받기 위해서는 적어도 2\~3 배수의 비동기 작업이 필요했는데, 이런 이유로 listenerExecutor 를 min =1, max =2 으로 두어서 스레드 풀을 설정했습니다. 데이터 수신의 경우 데이터 수신 외에는 별도의 IO 작업이 없었고 캐시에 데이터를 적재하는 역할만을 수행하는데, 캐시에 데이터가 적재되는 속도를 직접 체크해본 결과 최대 3ns 안에 이루어졌기에 실제로는 그렇게 큰 스레드 풀이 필요하지는 않았습니다.<br/>

데이터를 수신한 후 캐시에 쌓아둔 작업 대기열의 소비 작업은 schedulerExecutor 가 workerExecutor, pushExecutor 중 하나를 선택해서 해당 스레드를 실행시키도록 했습니다.<br/>



## 아쉬운 점

최근 webflux, kotlin coroutine 스터디 문서를 작성하면서 <br/>

> "자바의 스레드와 톰캣의 스레드 풀로 레피니티브의 고빈도 트래픽을 처리하는 건 정말 리소스를 비싸게 사용하는 것이었구나" 

<br/>

하는 생각을 했었습니다. 사실 그 당시 이 기능 개발 전 프로젝트 셋업 당시에 webflux 를 도입하려고 했지만 반대에 부딪혔었는데 만약 그 당시에 webflux 를 하겠다고 우기고 앞으로 나갔다면 지금은 어땠을까? 하고 생각해봤던 것 같습니다.<br/>

<br/>

스레드 하나에 작업 하나를 부여해서 그 작업을 비동기 논블로킹으로 연산했던 것들은 지금에 와서 돌아보면 "IO작업 하나에 정말 너무 비싼 비용을 치룬 것이 아닌가" 하는 생각을 너무나 자주 합니다. 톰캣의 스레드 풀 보다는 Netty 기반의 AIO 네트워킹 기반의 WAS 서버에서 프로젝트가 진행되었다면 조금은 프로젝트가 빨라졌지 않을까 하는 생각도 해봤던 것 같습니다.<br/>

<br/>



